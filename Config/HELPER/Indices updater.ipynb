{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6vPgvPGJeNKyb+qdi4Wbu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qp8cl9V3M4P_","executionInfo":{"status":"ok","timestamp":1745774062449,"user_tz":-330,"elapsed":1100,"user":{"displayName":"Sachin Dabhade","userId":"18155664819953204336"}},"outputId":"91388b35-45af-490b-acaa-b3f695c38ae7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading CSV from: https://nsearchives.nseindia.com/content/indices/ind_niftymidcap100list.csv\n","✅ CSV saved as: downloads/ind_niftymidcap100list.csv\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import re\n","import os\n","\n","def fetch_nse_index_csv(index_url, save_dir=\"downloads\"):\n","    headers = {\n","        \"User-Agent\": \"Mozilla/5.0\",\n","        \"Accept-Language\": \"en-US,en;q=0.9\",\n","        \"Referer\": \"https://www.nseindia.com\"\n","    }\n","\n","    # Step 1: Get HTML content\n","    session = requests.Session()\n","    session.get(\"https://www.nseindia.com\", headers=headers)  # Needed to set cookies\n","    response = session.get(index_url, headers=headers)\n","\n","    if response.status_code != 200:\n","        print(\"Failed to fetch page\")\n","        return\n","\n","    soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","    # Step 2: Find the .csv link\n","    csv_link = None\n","    for a_tag in soup.find_all(\"a\", href=True):\n","        href = a_tag[\"href\"]\n","        if \".csv\" in href:\n","            csv_link = href\n","            break\n","\n","    if not csv_link:\n","        print(\"CSV link not found.\")\n","        return\n","\n","    # Full link (relative to base domain if not absolute)\n","    if not csv_link.startswith(\"http\"):\n","        csv_link = \"https://www.niftyindices.com\" + csv_link\n","\n","    print(f\"Downloading CSV from: {csv_link}\")\n","\n","    # Step 3: Download and save the CSV\n","    csv_response = session.get(csv_link, headers=headers)\n","    if csv_response.status_code == 200:\n","        os.makedirs(save_dir, exist_ok=True)\n","        file_name = csv_link.split(\"/\")[-1]\n","        file_path = os.path.join(save_dir, file_name)\n","\n","        with open(file_path, \"wb\") as f:\n","            f.write(csv_response.content)\n","\n","        print(f\"✅ CSV saved as: {file_path}\")\n","    else:\n","        print(\"Failed to download CSV.\")\n","\n","# Example usage:\n","fetch_nse_index_csv(\"https://www.nseindia.com/products-services/indices-niftymidcap100-index\")"]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import os\n","\n","def download_csv_from_webpage(page_url, download_folder=\"INDEXES\"):\n","    try:\n","        # Step 1: Create the folder if it doesn't exist\n","        os.makedirs(download_folder, exist_ok=True)\n","\n","        # Step 2: Fetch the webpage\n","        response = requests.get(page_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","        response.raise_for_status()\n","\n","        # Step 3: Parse the page\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","\n","        # Step 4: Find the CSV link\n","        csv_link = None\n","        for a_tag in soup.find_all('a', href=True):\n","            href = a_tag['href']\n","            if href.endswith('.csv'):\n","                csv_link = href\n","                break\n","\n","        if not csv_link:\n","            print(\"❌ No CSV link found on the page.\")\n","            return\n","\n","        # Step 5: Handle relative link if needed\n","        if csv_link.startswith('/'):\n","            csv_link = \"https://www.niftyindices.com\" + csv_link\n","\n","        # Step 6: Download the CSV\n","        csv_response = requests.get(csv_link, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","        csv_response.raise_for_status()\n","\n","        file_name = os.path.join(download_folder, os.path.basename(csv_link))\n","\n","        with open(file_name, 'wb') as f:\n","            f.write(csv_response.content)\n","\n","        print(f\"✅ CSV downloaded successfully and saved at: {file_name}\")\n","\n","    except Exception as e:\n","        print(f\"❌ Error: {e}\")\n","\n"],"metadata":{"id":"zq_bnm4BQ6Jg","executionInfo":{"status":"ok","timestamp":1745774581192,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sachin Dabhade","userId":"18155664819953204336"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["download_csv_from_webpage(\"https://www.niftyindices.com/indices/equity/sectoral-indices/nifty-auto\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YeGJaR5XQ7HT","executionInfo":{"status":"ok","timestamp":1745774583397,"user_tz":-330,"elapsed":488,"user":{"displayName":"Sachin Dabhade","userId":"18155664819953204336"}},"outputId":"17b2ce88-aa96-4592-9c7d-b296e135edbe"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["❌ Error: Invalid URL '../../../IndexConstituent/ind_niftyautolist.csv': No scheme supplied. Perhaps you meant https://../../../IndexConstituent/ind_niftyautolist.csv?\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"aC5QpQmvQ_Yw"},"execution_count":null,"outputs":[]}]}